[
  {
    "combo": "Vector+LLaMA",
    "setup_metrics": {
      "total_ms": 16028.8,
      "embedding_ms": 16018.9,
      "tokenizing_ms": 0.0,
      "indexing_ms": 4.3,
      "memory_peak_mb": 1.04,
      "storage_mb": 0.0
    },
    "latency": {
      "avg_retrieval_ms": 156.2,
      "avg_generation_ms": 903.1,
      "avg_total_ms": 1059.3,
      "avg_tokens": 1005.6
    },
    "quality": {
      "faithfulness": 0.9,
      "answer_relevancy": 0.94,
      "context_relevancy": 0.92,
      "completeness": 0.74,
      "average": 0.875
    },
    "per_question": [
      {
        "question": "What is the difference between BERT and GPT?",
        "retrieval_ms": 425.8,
        "generation_ms": 2212.4,
        "tokens": 1086
      },
      {
        "question": "How does key value caching improve transformer inference?",
        "retrieval_ms": 182.5,
        "generation_ms": 726.9,
        "tokens": 978
      },
      {
        "question": "What are the trade-offs between dense and sparse retrieval?",
        "retrieval_ms": 43.6,
        "generation_ms": 857.0,
        "tokens": 983
      },
      {
        "question": "What is the attention mechanism in transformers?",
        "retrieval_ms": 55.9,
        "generation_ms": 346.4,
        "tokens": 983
      },
      {
        "question": "What is the difference between top-k and top-p sampling?",
        "retrieval_ms": 73.2,
        "generation_ms": 372.9,
        "tokens": 998
      }
    ]
  },
  {
    "combo": "BM25+LLaMA",
    "setup_metrics": {
      "total_ms": 187.5,
      "embedding_ms": 0.0,
      "tokenizing_ms": 143.2,
      "indexing_ms": 40.2,
      "memory_peak_mb": 1.91,
      "storage_mb": 0.0
    },
    "latency": {
      "avg_retrieval_ms": 3.1,
      "avg_generation_ms": 4174.9,
      "avg_total_ms": 4177.9,
      "avg_tokens": 983.0
    },
    "quality": {
      "faithfulness": 0.86,
      "answer_relevancy": 0.88,
      "context_relevancy": 0.92,
      "completeness": 0.6,
      "average": 0.815
    },
    "per_question": [
      {
        "question": "What is the difference between BERT and GPT?",
        "retrieval_ms": 2.3,
        "generation_ms": 1843.7,
        "tokens": 1048
      },
      {
        "question": "How does key value caching improve transformer inference?",
        "retrieval_ms": 5.7,
        "generation_ms": 4497.9,
        "tokens": 970
      },
      {
        "question": "What are the trade-offs between dense and sparse retrieval?",
        "retrieval_ms": 3.7,
        "generation_ms": 4497.9,
        "tokens": 893
      },
      {
        "question": "What is the attention mechanism in transformers?",
        "retrieval_ms": 1.8,
        "generation_ms": 5528.1,
        "tokens": 983
      },
      {
        "question": "What is the difference between top-k and top-p sampling?",
        "retrieval_ms": 1.8,
        "generation_ms": 4506.8,
        "tokens": 1021
      }
    ]
  },
  {
    "combo": "Hybrid+LLaMA",
    "setup_metrics": {
      "total_ms": 18376.5,
      "embedding_ms": 18179.1,
      "tokenizing_ms": 147.9,
      "indexing_ms": 43.6,
      "memory_peak_mb": 1.93,
      "storage_mb": 0.0
    },
    "latency": {
      "avg_retrieval_ms": 57.7,
      "avg_generation_ms": 5043.1,
      "avg_total_ms": 5100.8,
      "avg_tokens": 994.8
    },
    "quality": {
      "faithfulness": 0.9,
      "answer_relevancy": 0.94,
      "context_relevancy": 0.88,
      "completeness": 0.78,
      "average": 0.875
    },
    "per_question": [
      {
        "question": "What is the difference between BERT and GPT?",
        "retrieval_ms": 67.6,
        "generation_ms": 5835.4,
        "tokens": 1048
      },
      {
        "question": "How does key value caching improve transformer inference?",
        "retrieval_ms": 52.3,
        "generation_ms": 4798.5,
        "tokens": 978
      },
      {
        "question": "What are the trade-offs between dense and sparse retrieval?",
        "retrieval_ms": 59.5,
        "generation_ms": 4993.5,
        "tokens": 948
      },
      {
        "question": "What is the attention mechanism in transformers?",
        "retrieval_ms": 50.8,
        "generation_ms": 4457.7,
        "tokens": 979
      },
      {
        "question": "What is the difference between top-k and top-p sampling?",
        "retrieval_ms": 58.3,
        "generation_ms": 5130.3,
        "tokens": 1021
      }
    ]
  }
]