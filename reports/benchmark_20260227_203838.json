[
  {
    "combo": "Vector+LLaMA",
    "setup_metrics": {
      "total_ms": 14459.8,
      "embedding_ms": 14452.5,
      "tokenizing_ms": 0.0,
      "indexing_ms": 3.8,
      "memory_peak_mb": 1.04,
      "storage_mb": 0.0
    },
    "latency": {
      "avg_retrieval_ms": 27.2,
      "avg_generation_ms": 516.9,
      "avg_total_ms": 544.2,
      "avg_tokens": 994.6
    },
    "quality": {
      "faithfulness": 0.9,
      "answer_relevancy": 0.94,
      "context_relevancy": 0.92,
      "completeness": 0.74,
      "average": 0.875
    },
    "per_question": [
      {
        "question": "What is the difference between BERT and GPT?",
        "retrieval_ms": 27.8,
        "generation_ms": 956.8,
        "tokens": 1050
      },
      {
        "question": "How does key value caching improve transformer inference?",
        "retrieval_ms": 27.8,
        "generation_ms": 379.2,
        "tokens": 978
      },
      {
        "question": "What are the trade-offs between dense and sparse retrieval?",
        "retrieval_ms": 24.3,
        "generation_ms": 593.1,
        "tokens": 964
      },
      {
        "question": "What is the attention mechanism in transformers?",
        "retrieval_ms": 28.6,
        "generation_ms": 378.0,
        "tokens": 983
      },
      {
        "question": "What is the difference between top-k and top-p sampling?",
        "retrieval_ms": 27.7,
        "generation_ms": 277.6,
        "tokens": 998
      }
    ]
  },
  {
    "combo": "BM25+LLaMA",
    "setup_metrics": {
      "total_ms": 238.8,
      "embedding_ms": 0.0,
      "tokenizing_ms": 171.5,
      "indexing_ms": 61.2,
      "memory_peak_mb": 1.91,
      "storage_mb": 0.0
    },
    "latency": {
      "avg_retrieval_ms": 2.8,
      "avg_generation_ms": 4091.6,
      "avg_total_ms": 4094.4,
      "avg_tokens": 992.6
    },
    "quality": {
      "faithfulness": 0.86,
      "answer_relevancy": 0.86,
      "context_relevancy": 0.92,
      "completeness": 0.6,
      "average": 0.81
    },
    "per_question": [
      {
        "question": "What is the difference between BERT and GPT?",
        "retrieval_ms": 1.6,
        "generation_ms": 1435.3,
        "tokens": 1098
      },
      {
        "question": "How does key value caching improve transformer inference?",
        "retrieval_ms": 2.8,
        "generation_ms": 4496.3,
        "tokens": 969
      },
      {
        "question": "What are the trade-offs between dense and sparse retrieval?",
        "retrieval_ms": 3.2,
        "generation_ms": 4606.5,
        "tokens": 892
      },
      {
        "question": "What is the attention mechanism in transformers?",
        "retrieval_ms": 2.6,
        "generation_ms": 4407.8,
        "tokens": 983
      },
      {
        "question": "What is the difference between top-k and top-p sampling?",
        "retrieval_ms": 3.7,
        "generation_ms": 5512.2,
        "tokens": 1021
      }
    ]
  },
  {
    "combo": "Hybrid+LLaMA",
    "setup_metrics": {
      "total_ms": 12346.3,
      "embedding_ms": 12163.9,
      "tokenizing_ms": 133.1,
      "indexing_ms": 43.4,
      "memory_peak_mb": 1.93,
      "storage_mb": 0.0
    },
    "latency": {
      "avg_retrieval_ms": 41.8,
      "avg_generation_ms": 4892.9,
      "avg_total_ms": 4934.8,
      "avg_tokens": 994.4
    },
    "quality": {
      "faithfulness": 0.88,
      "answer_relevancy": 0.92,
      "context_relevancy": 0.88,
      "completeness": 0.74,
      "average": 0.855
    },
    "per_question": [
      {
        "question": "What is the difference between BERT and GPT?",
        "retrieval_ms": 36.0,
        "generation_ms": 4695.3,
        "tokens": 1045
      },
      {
        "question": "How does key value caching improve transformer inference?",
        "retrieval_ms": 48.4,
        "generation_ms": 5863.8,
        "tokens": 994
      },
      {
        "question": "What are the trade-offs between dense and sparse retrieval?",
        "retrieval_ms": 56.3,
        "generation_ms": 4551.7,
        "tokens": 933
      },
      {
        "question": "What is the attention mechanism in transformers?",
        "retrieval_ms": 34.9,
        "generation_ms": 4776.5,
        "tokens": 979
      },
      {
        "question": "What is the difference between top-k and top-p sampling?",
        "retrieval_ms": 33.6,
        "generation_ms": 4577.2,
        "tokens": 1021
      }
    ]
  }
]